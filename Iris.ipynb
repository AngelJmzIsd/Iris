{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnsNxO93GZx4cZRFSFQ/5L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelJmzIsd/Iris/blob/main/Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  _____      _       _____           _                    \n",
        "# |_   _|    (_)     |  __ \\         | |                   \n",
        "#   | |  _ __ _ ___  | |__) |_ _  ___| | ____ _  __ _  ___ \n",
        "#   | | | '__| / __| |  ___/ _` |/ __| |/ / _` |/ _` |/ _ \\\n",
        "#  _| |_| |  | \\__ \\ | |  | (_| | (__|   < (_| | (_| |  __/\n",
        "# |_____|_|  |_|___/ |_|   \\__,_|\\___|_|\\_\\__,_|\\__, |\\___|\n",
        "#                                                __/ |     \n",
        "#                                               |___/      "
      ],
      "metadata": {
        "id": "j21df9YPD8JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este modulo tiene el objetivo de hacer más fácil el proceso de limpieza, seleccion de features y evaluacion de modelos de ML para el reto de Ternium.\n",
        "\n",
        "---\n",
        "Fue creado en base a un interés personal por acelerar y agilizar los procesos de limpieza, entrenamiento y evaluación de modelos, así como de poder escribir un codigo mucho más comprensible y conciso, al mismo tiempo que preciso.\n",
        "\n",
        "\n",
        "---\n",
        "EXPLICACION DE LOS NOMBRES: \n",
        "\n",
        "El primer arbol de decisiones que realice fue analizando el dataset de las flores Iris, un conjunto de datos utilizado ampliamente para aprender ciencia de datos, modelos de clasificacion, y basicamente, introducirse en el mundo de la Inteligencia Artificial.\n",
        "\n",
        "---\n",
        "\n",
        "Por el momento se contemplan dos clases:\n",
        "\n",
        " - **Versicolor:** creada en base a un dataframe de pandas, las funciones miembre tienen el objetivo de transformar, manipular y limpiar la base de datos, más no de entrenar o evaluar los modelo.\n",
        "\n",
        "\n",
        " - **Setosa**: esta tiene el objetivo de "
      ],
      "metadata": {
        "id": "ZuCIO5ArXqNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTA: El 15 de junio de 2022 a las 00:14 se cambio el nombre de \"Versicolor\" a\n",
        "\n",
        "\"Iris\", los nombres de las clases pasan a ser \"Versicolor\" (antes \"Dataset\") y \n",
        "\n",
        "\"Setosa\" (antes \"Evaluador\"). "
      ],
      "metadata": {
        "id": "94kPCFE5yPNv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILMePClAXZEd"
      },
      "outputs": [],
      "source": [
        "#Importar librerias principales\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#Seleccion de features\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "\n",
        "#Transformacion de datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#Modelos de clasificacion\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "\n",
        "\n",
        "#EVALUACION DE MODELOS\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#   _____\n",
        "#  / ____| |               \\ \\    / /          (_)         | |           \n",
        "# | |    | | __ _ ___ ___   \\ \\  / /__ _ __ ___ _  ___ ___ | | ___  _ __ \n",
        "# | |    | |/ _` / __/ __|   \\ \\/ / _ \\ '__/ __| |/ __/ _ \\| |/ _ \\| '__|\n",
        "# | |____| | (_| \\__ \\__ \\    \\  /  __/ |  \\__ \\ | (_| (_) | | (_) | |   \n",
        "#  \\_____|_|\\__,_|___/___/     \\/ \\___|_|  |___/_|\\___\\___/|_|\\___/|_|   \n",
        "                                                                      \n",
        "\n",
        "'''\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "Es la clase Versicolor que en realidad es lo mismo que un dataframe, solo que\n",
        "le puse funciones para hacer la limpieza y la descripcion de forma mas rapida\n",
        "#y el codigo más entendible\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "'''\n",
        "\n",
        "class Versicolor:\n",
        "\n",
        "  #Dataframe que guarda el estado original del objeto, aunque se contempla\n",
        "  #eliminarlo pronto, por el uso de la memoria\n",
        "\n",
        "  dfRespaldo=pd.DataFrame()\n",
        "\n",
        "  nombreTarget=[]\n",
        "\n",
        "\n",
        "\n",
        "  #Df = objeto dataframe de pandas\n",
        "  #Nombre = etiqueta o alias tipo string para asignarle una descripcion\n",
        "  #Por ejemplo alias=\"datos crudos, sin limpiar\"\n",
        "\n",
        "  def __init__(self,dataframe, nombre):\n",
        "    self.dataframe=pd.DataFrame()\n",
        "    self.dataframe=dataframe.copy()\n",
        "    self.dfRespaldo=self.dataframe.copy()\n",
        "    self.nombre=nombre\n",
        "\n",
        "\n",
        "  #Funcion para obtener los nombres de las variables que son de tipo object y\n",
        "  #que posiblemente son categoricas\n",
        "\n",
        "  def setNombreTarget(self,nombreColumnaTarget):\n",
        "    self.nombreTarget.append(nombreColumnaTarget)\n",
        "    return None\n",
        "\n",
        "  def getNombresNumericas(self):\n",
        "    camposNumericos=[]\n",
        "    campos=self.dataframe.columns\n",
        "    n=len(campos)\n",
        "\n",
        "    for i in range(0,n):\n",
        "      nombreCampo=campos[i]\n",
        "      tipoCampo=self.dataframe[nombreCampo].dtype.name\n",
        "      if (tipoCampo == 'int64' or tipoCampo=='float64'):\n",
        "        camposNumericos.append(nombreCampo)\n",
        "\n",
        "    return camposNumericos\n",
        "\n",
        "\n",
        "\n",
        "  def getNombresNoNumericas(self):\n",
        "    camposNoNumericos=[]\n",
        "    campos=self.dataframe.columns\n",
        "    n=len(campos)\n",
        "\n",
        "    for i in range(0,n):\n",
        "      nombreCampo=campos[i]\n",
        "      tipoCampo=self.dataframe[nombreCampo].dtype.name\n",
        "      if (tipoCampo == 'object'):\n",
        "        camposNoNumericos.append(nombreCampo)\n",
        "\n",
        "    return camposNoNumericos\n",
        "\n",
        "\n",
        "#Regresa el datagrame a su estado original, mediante l \n",
        "  def reset(self):\n",
        "    self.dataframe=self.dfRespaldo.copy()\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "#\n",
        "#                           LIMPIEZA DE DATOS\n",
        "#\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# Funcion para obtener nombres columnas redundantes con un solo \n",
        "#valor o todos null\n",
        "  def getColumnasVacias(self):\n",
        "    columnas=list(self.dataframe.columns)\n",
        "    redundantes=[]\n",
        "    n=len(columnas)\n",
        "\n",
        "    for i in range (0,n):\n",
        "      columna=str(columnas[i])\n",
        "      valoresUnicos=len(pd.unique(self.dataframe[columna]))\n",
        "      if (valoresUnicos <= 1): redundantes.append(columna)\n",
        "\n",
        "    return redundantes\n",
        "\n",
        "\n",
        "  #Funcion para quitar un conjunto de columnas del dataset\n",
        "  def quitarColumnas(self,nombresColumnas):\n",
        "    self.dataframe=self.dataframe.drop(columns=nombresColumnas)\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "  # Primero calcula los limites superiores e inferiores de cada columna, luego\n",
        "  # quita la\n",
        "  def contarAtipicosPorColumnas(self,nombresColumnas):\n",
        "    #Crear un nuevo dataframe solo con las columnas deseadas\n",
        "    df=pd.DataFrame()\n",
        "    for col in nombresColumnas:\n",
        "      df[col]=self.dataframe[col].copy()\n",
        "\n",
        "    #Calcular las metricas para cada uno de las cosas esas\n",
        "\n",
        "    q1=list(df.quantile(0.25))\n",
        "    q3=list(df.quantile(0.75))\n",
        "    q1=pd.Series(q1)\n",
        "    q3=pd.Series(q3)\n",
        "\n",
        "    rango=q3-q1\n",
        "    limSup=q3+1.5*rango\n",
        "    limInf=q1-1.5*rango\n",
        "\n",
        "    rango=list(rango)\n",
        "    limSup=list(limSup)\n",
        "    limInf=list(limInf)\n",
        "\n",
        "    cantidadAtipicos=[]\n",
        "    n=len(nombresColumnas)\n",
        "\n",
        "    for i in range (0,n):\n",
        "      columna=nombresColumnas[i]\n",
        "\n",
        "      dfAux=pd.DataFrame()\n",
        "      dfAux= self.dataframe[      (self.dataframe[columna] < limInf[i]) or (self.dataframe[columna] > limSup[i])     ]\n",
        "\n",
        "      cantidadAtipicos.append(dfAux.shape[0])\n",
        "\n",
        "    return cantidadAtipicos\n",
        "  #Recorre cada columna y quita la fila si encuentra un atipico\n",
        "  def quitarAtipicosPorColumnas(self,nombresColumnas):\n",
        "    return 0\n",
        "\n",
        "  \n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "  #PRIORITARIOS\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "  def contarFaltantesColumnas(self,nombresColumnas,porcentaje):\n",
        "    cantidadFaltantes=[]\n",
        "    n=len(nombresColumnas)\n",
        "\n",
        "    for i in range(0,n):\n",
        "      columna=nombresColumnas[i]\n",
        "      nulos=self.dataframe[columna].isna().sum()\n",
        "\n",
        "      if(porcentaje==True): nulos = (100*nulos/self.dataframe.shape[0])\n",
        "      cantidadFaltantes.append(nulos)\n",
        "    \n",
        "    return cantidadFaltantes\n",
        "\n",
        "  def contarFaltantesColumnasCustom(self,nombresColumnas,porcentaje,customNa):\n",
        "    cantidadFaltantes=[]\n",
        "    n=len(nombresColumnas)\n",
        "\n",
        "    for i in range(0,n):\n",
        "      columna=nombresColumnas[i]\n",
        "      nulos=self.dataframe[ self.dataframe[columna]==customNa]\n",
        "      faltantes=nulos.sum()\n",
        "      #nulos=self.dataframe[columna].isna().sum()\n",
        "\n",
        "      if(porcentaje==True): faltantes = (100*faltantes/self.dataframe.shape[0])\n",
        "      cantidadFaltantes.append(faltantes)\n",
        "    \n",
        "    return cantidadFaltantes\n",
        "\n",
        "  def getColumnasVaciasPorcentajeMenorIgualA(self,porcentaje):\n",
        "    columnas=list(self.dataframe.columns)\n",
        "    porcentajeFaltantes=self.contarFaltantesColumnas(columnas,True)\n",
        "\n",
        "    vaciasPorcentaje=[]\n",
        "    n=len(columnas)\n",
        "\n",
        "    for i in range(0,n):\n",
        "      if (porcentajeFaltantes[i]<=porcentaje):\n",
        "        vaciasPorcentaje.append(columnas[i])\n",
        "    return vaciasPorcentaje\n",
        "\n",
        "  def getColumnasVaciasPorcentajeMayorA(self,porcentaje):\n",
        "    columnas=list(self.dataframe.columns)\n",
        "    porcentajeFaltantes=self.contarFaltantesColumnas(columnas,True)\n",
        "\n",
        "    vaciasPorcentaje=[]\n",
        "    n=len(columnas)\n",
        "\n",
        "    for i in range(0,n):\n",
        "      if (porcentajeFaltantes[i]>porcentaje):\n",
        "        vaciasPorcentaje.append(columnas[i])\n",
        "    return vaciasPorcentaje\n",
        "\n",
        "  #def porcentajeFaltantesColumnas(self,nombresColumnas):\n",
        "    #return 0\n",
        "\n",
        "\n",
        "  #medida = \"moda\",\"promedio\",\"mediana\"\n",
        "  def reemplazarFaltantesColumnas(self,nombresColumnas,medida):\n",
        "    n=len(nombresColumnas)\n",
        "\n",
        "    if (medida==\"promedio\"):\n",
        "      for i in range(0,n):\n",
        "        columna=nombresColumnas[i]\n",
        "        self.dataframe[columna]=self.dataframe[columna].fillna(self.dataframe[columna].mean())\n",
        "\n",
        "    if (medida==\"mediana\"):\n",
        "      for i in range(0,n):\n",
        "        columna=nombresColumnas[i]\n",
        "        self.dataframe[columna]=self.dataframe[columna].fillna(self.dataframe[columna].median())\n",
        "\n",
        "    if (medida==\"moda\"):\n",
        "      for i in range(0,n):\n",
        "        columna=nombresColumnas[i]\n",
        "        moda=list(self.dataframe[columna].mode().squeeze())[0]\n",
        "        self.dataframe[columna]=self.dataframe[columna].fillna(moda)\n",
        "    return 0\n",
        "\n",
        "\n",
        "  def reemplazarFaltantesColumnasCustom(self,nombresColumnas,medida,customNa):\n",
        "\n",
        "    n=len(nombresColumnas)\n",
        "\n",
        "    if (medida==\"promedio\"):\n",
        "      for i in range(0,n):\n",
        "        columna=nombresColumnas[i]\n",
        "        #self.dataframe[columna].fillna(self.dataframe[columna].mean(),inplace = True)\n",
        "\n",
        "    if (medida==\"mediana\"):\n",
        "      for i in range(0,n):\n",
        "        columna=nombresColumnas[i]\n",
        "        #self.dataframe[columna].fillna(self.dataframe[columna].median(),inplace = True)\n",
        "\n",
        "    if (medida==\"moda\"):\n",
        "      for i in range(0,n):\n",
        "        columna=nombresColumnas[i]\n",
        "        moda=list(self.dataframe[columna].mode().squeeze())[0]\n",
        "        self.dataframe[columna] = np.where(self.dataframe[columna] == customNa, moda,self.dataframe[columna])\n",
        "    return 0\n",
        "\n",
        "  def exportarCsv(self,ruta,codificacion):\n",
        "    if (codificacion==0):\n",
        "      self.dataframe.to_csv(ruta,encoding='latin-1')\n",
        "    else:\n",
        "      self.dataframe.to_csv(ruta,encoding=codificacion)\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "#\n",
        "#       FUNCIONES PARA SELECCION DE CARACTERISTICAS\n",
        "#\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "\n",
        "  def setFeatures():\n",
        "    return 0\n",
        "\n",
        "  def setTarget():\n",
        "    return 0\n",
        "\n",
        "  def getFeatures():\n",
        "    return 0\n",
        "\n",
        "  def getTarget():\n",
        "    return 0\n",
        "\n",
        "\n",
        "  def getTargetBinarioDefecto(self,nombreColumnaTarget,nombreDefecto):\n",
        "    columna=self.dataframe[nombreColumnaTarget].copy()\n",
        "    df=pd.DataFrame()\n",
        "    df[nombreDefecto]=np.where(self.dataframe[nombreColumnaTarget] == nombreDefecto, 1, 0)\n",
        "    return df[nombreDefecto].copy()\n",
        "\n",
        "  def getKbestChi2DefectoIndividual(self,nombreColumnaTarget,nombreDefecto,numeroFeatures):\n",
        "    \n",
        "    \n",
        "    #features=self.dataframe.copy()\n",
        "    target=self.getTargetBinarioDefecto(nombreColumnaTarget,nombreDefecto)\n",
        "    nombresNumericas=self.getNombresNumericas()\n",
        "    dfNumericas=pd.DataFrame()\n",
        "\n",
        "    #Crear nuevo dataframe con puras columnas numericas y al final agregarle\n",
        "    #la variable Target\n",
        "\n",
        "    for nombre in nombresNumericas:\n",
        "      dfNumericas[nombre]=self.dataframe[nombre].copy()\n",
        "    dfNumericas['class']=target.copy()\n",
        "\n",
        "    M=len(dfNumericas.columns)\n",
        "    array = dfNumericas.values\n",
        "\n",
        "    X = array[:,0:M-1]\n",
        "    Y = array[:,M-1]\n",
        "\n",
        "    test=SelectKBest(score_func=chi2, k=numeroFeatures)\n",
        "    fit = test.fit(X, Y)\n",
        "    puntajes=fit.scores_\n",
        "    features = fit.transform(X)\n",
        "\n",
        "    campos=list(dfNumericas.columns[0:-1])\n",
        "    scores=list(puntajes)\n",
        "\n",
        "    indices=[]\n",
        "\n",
        "    for i in range(0,len(campos)+1):\n",
        "      indices.append(i)\n",
        "\n",
        "    nombreCamposSeleccionados=[]\n",
        "    scoreSeleccionados=[]\n",
        "    posicionCamposSeleccionados=[]\n",
        "    rank=[]\n",
        "\n",
        "    #AHORA VOY A HACER UN CICLO FOR QUE ENCUENTRE EL INDICE DEL MAXIMO VALOR EN LA LISTA DE SCORES Y LO VAYA GUARDANDO Y REPITA ESTO 1O VECES\n",
        "\n",
        "\n",
        "    for i in range(0,numeroFeatures):\n",
        "      scoreMaximo=0\n",
        "      indiceMaximo=0\n",
        "      nombreCampoMaximo=\"\"\n",
        "\n",
        "      scoreMaximo=max(scores)\n",
        "      indiceMaximo=scores.index(scoreMaximo)\n",
        "\n",
        "      posicionEnOriginal=indices[indiceMaximo]\n",
        "\n",
        "      #Guardar los datos de los maximos\n",
        "\n",
        "      scoreSeleccionados.append(scoreMaximo)\n",
        "      posicionCamposSeleccionados.append(indices[indiceMaximo])\n",
        "      nombreCamposSeleccionados.append(campos[indiceMaximo])\n",
        "      rank.append(i+1)\n",
        "\n",
        "      #Borrar los datos\n",
        "      del campos[indiceMaximo]\n",
        "      del scores[indiceMaximo]\n",
        "      del indices[indiceMaximo]\n",
        "\n",
        "    features=[nombreCamposSeleccionados,scoreSeleccionados,posicionCamposSeleccionados,rank]\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "#\n",
        "#       FUNCIONES PARA TRANSFORMACION\n",
        "#\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "\n",
        "  def estandarizar(self,nombresColumnas):\n",
        "    \n",
        "    return 0\n",
        "\n",
        "\n",
        "  def convertirCategoricasToBinaria(self,nombresCategoricas):\n",
        "\n",
        "    columnas=nombresCategoricas #lista de strings con nombres de las columnas\n",
        "    columnasToDrop=self.getNombresNumericas()+self.nombreTarget\n",
        "\n",
        "    df_NoNumericas=self.dataframe.drop(columns=columnasToDrop).copy()\n",
        "    df_NoNumericas=pd.get_dummies(df_NoNumericas)\n",
        "\n",
        "    self.quitarColumnas(nombresCategoricas)\n",
        "\n",
        "    nombresBinarias=list(df_NoNumericas.columns)\n",
        "    nombresBinarias.reverse()\n",
        "\n",
        "    #Agregar las columnas creadas al inicio del dataframe original\n",
        "    for columna in nombresBinarias:\n",
        "      self.datagrame.insert(loc=0, column=columna, value=df_NoNumericas[columna])\n",
        "    return None\n",
        "\n",
        "  def convertirTargetToBinaria(self):\n",
        "    targets=self.nombreTarget=[]\n",
        "    self.nombreTarget=[]\n",
        "    columnas=nombresCategoricas #lista de strings con nombres de las columnas\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "#       EXCLUSIVAS PARA EL PROBLEMA DE TERNIUM\n",
        "#       EXCLUSIVAS PARA EL PROBLEMA DE TERNIUM\n",
        "#       EXCLUSIVAS PARA EL PROBLEMA DE TERNIUM\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "#\n",
        "#       FUNCIONES PARA GRAFICACION\n",
        "#\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#'''\n",
        "# DESCRIPCION DE DATOS: Graficacion y resumen\n",
        "# ##############################################################################\n",
        "#'''\n",
        "\n",
        "# Tratamiento de datos\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# GRAFICACION DESCRIPTIVA - RESUMEN\n",
        "# ==============================================================================\n",
        "\n",
        "# GRAFICACION DESCRIPTIVA - RESUMEN\n",
        "# ==============================================================================\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EIFGTxZpZCII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   _____ _                   _____      _                  \n",
        "#  / ____| |                 / ____|    | |                 \n",
        "# | |    | | __ _ ___ ___   | (___   ___| |_ ___  ___  __ _ \n",
        "# | |    | |/ _` / __/ __|   \\___ \\ / _ \\ __/ _ \\/ __|/ _` |\n",
        "# | |____| | (_| \\__ \\__ \\   ____) |  __/ || (_) \\__ \\ (_| |\n",
        "#  \\_____|_|\\__,_|___/___/  |_____/ \\___|\\__\\___/|___/\\__,_|\n",
        "#                                                           \n",
        "                                                                                                                                                                                             \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "\n",
        "# ESTA CLASE ESTA PENSADA PARA HACER EL PROCESO DE ENTRENAMIENO Y EVALUACION DE\n",
        "MODELOS DE MANERA MAS RAPIDA, PRACTICA Y ENTENDIBLE.\n",
        "\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "'''\n",
        "#Clase para evaluar los modelos de entrenamiento\n",
        "#Como parámetros se le deben de dar los features y el target, en forma de \n",
        "#dataframe o series.\n",
        "\n",
        "class Setosa:\n",
        "\n",
        "  #Estas de aqui son condiciones Booleanas, que por el momento no se han usado\n",
        "  #pero que estan planeadas para mostrara avisos y mensajes de error.\n",
        "  #Por ejenplo, mostrar un error si se quiere mostrar el reporte del arbol\n",
        "  #pero aun no se ha entrenado el modelo\n",
        "  arbolEntrenado=False\n",
        "  regresionLogisticaEntrenado=False\n",
        "  svmEntrenado=False\n",
        "\n",
        "  #Los conjuntos de entrenamiento y de prueba son guardados como atributos\n",
        "  #internos de la clase, de esta manera, cualquier modelo de clasificacion\n",
        "  #dentro de la clase puede acceder a ellos sin tener que volver a crearlos\n",
        "  x_train=[]\n",
        "  x_test=[]\n",
        "  y_train=[]\n",
        "  y_test=[]\n",
        "\n",
        "  #Las predicciones de cada modelo tambien se guardan como atributos de clase\n",
        "  #con el objetivo de que al realizar los reportes de metricas no se tenga que\n",
        "  #calcular nuevamente las predicciones ni que se agregen lineas de mas\n",
        "  y_predicted_arbol=[]\n",
        "  y_predicted_logreg=[]\n",
        "  y_predicted_svm=[]\n",
        "\n",
        "\n",
        "  #Asimismo, los modelos de clasificacion se guardan de forma interna como\n",
        "  #atributos de la clase, de tal maneta que cualquier funcion miembro puede\n",
        "  #puede acceder a ellos\n",
        "\n",
        "  #PRE-CREACION DE MODELOS\n",
        "  arbol= tree.DecisionTreeClassifier()\n",
        "  logRec = LogisticRegression(solver='liblinear', random_state=0)\n",
        "\n",
        "  #Para el svm\n",
        "  pipeline= make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "  svm=make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "\n",
        "\n",
        "  #LA funcion que inicializa el objeto, se requieren como parametros, las\n",
        "  #columnas de features y la columna del target, en forma de dataframe o serie\n",
        "  #de Pandas\n",
        "  def __init__(self,features,target):\n",
        "    self.features=pd.DataFrame()\n",
        "    self.target=pd.DataFrame()\n",
        "    self.features=features.copy()\n",
        "    self.target=target.copy()\n",
        "\n",
        "\n",
        "  #Funcion que genera los conjuntos de entrenamiento y de prueba.\n",
        "  #Como parametros se requieren el test size y el random state\n",
        "  def generarSetsTrainTest(self,porcentajeTest,seed):\n",
        "    x=self.features\n",
        "    y=self.target\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(x, y, test_size = porcentajeTest, random_state = seed)\n",
        "    return None\n",
        "\n",
        "\n",
        "  #Con esta funcion se entrena el modelo de arbol de decisiones\n",
        "  #como parametros se requiere el random state y el la profunidad maxima\n",
        "  #Si el parametro de profundidad es menor o igual que cero, entonces se \n",
        "  #asume que no hay limite de profunidad\n",
        "  def entrenarArbol(self,seed,profundidadMax):\n",
        "\n",
        "    if (profundidadMax <= 0):\n",
        "      self.arbol=tree.DecisionTreeClassifier(random_state=seed)\n",
        "      self.arbol = self.arbol.fit(self.x_train, self.y_train)\n",
        "      self.y_predicted_arbol=self.arbol.predict(self.x_test)\n",
        "    else:\n",
        "      self.arbol=tree.DecisionTreeClassifier(random_state=seed,max_depth=profundidadMax)\n",
        "      self.arbol = self.arbol.fit(self.x_train, self.y_train)\n",
        "      self.y_predicted_arbol=self.arbol.predict(self.x_test)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "  #Como indica su nombre, este metodo entrena el modelo de regresion logistica\n",
        "  #que hay internamente\n",
        "  def entrenarRegresionLogistica(self):\n",
        "    self.logRec.fit(self.x_train, self.y_train)\n",
        "    self.y_predicted_logreg=self.logRec.predict(self.x_test)\n",
        "    return None\n",
        "\n",
        "  #Del mismo modo, esta funcion entrena el modelo SVM\n",
        "  def entrenarSVM(self):\n",
        "    self.svm=self.pipeline.fit(self.x_train, self.y_train)\n",
        "    self.y_predicted_svm=self.svm.predict(self.x_test)\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "  #\n",
        "  def evaluarModelo(self,nombreClasificador):\n",
        "\n",
        "    if nombreClasificador==\"arbol\":\n",
        "      clasificador=self.arbol\n",
        "      y_predicted=self.y_predicted_arbol\n",
        "    if nombreClasificador==\"logreg\":\n",
        "      clasificador=self.logRec\n",
        "      y_predicted=self.y_predicted_logreg\n",
        "    if nombreClasificador==\"svm\":\n",
        "      clasificador=self.svm\n",
        "      y_predicted=self.y_predicted_svm\n",
        "\n",
        "    #Matriz de confussion array\n",
        "    matriz=confusion_matrix(self.y_test,y_predicted,labels=clasificador.classes_)\n",
        "    \n",
        "    #Accuracy\n",
        "    accuracy=accuracy_score(self.y_test,y_predicted)\n",
        "\n",
        "    #Precission\n",
        "    precision=precision_score(self.y_test, y_predicted)\n",
        "\n",
        "    #Recall (sensibilidad)\n",
        "    recall=recall_score(self.y_test, y_predicted)\n",
        "\n",
        "    #Specificity\n",
        "    tn, fp, fn, tp = matriz.ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "\n",
        "    #F1-SCORE\n",
        "    f1=f1_score(self.y_test, y_predicted)\n",
        "\n",
        "\n",
        "\n",
        "    #AUC\n",
        "    #NOTA: Este calculo no esta correcto, se debe corregir, la verdadera AUC se\n",
        "    #muestra en la grafica generada de ROC\n",
        "    #se calcula est metrica pero no se muestra en el reporte individual\n",
        "    #se planea corregir luego\n",
        "    if nombreClasificador==\"svm\":\n",
        "      auc_score=roc_auc_score(self.y_train, clasificador.decision_function(self.x_train))\n",
        "    else:\n",
        "      auc_score=roc_auc_score(self.y_train, clasificador.predict_proba(self.x_train)[:, 1])\n",
        "\n",
        "\n",
        "    #Todas las variables se guardan en una lista, y la funcion regresa dicha\n",
        "    #lista con las metricas\n",
        "    metricas=[accuracy,precision,recall,specificity,f1,auc_score]\n",
        "\n",
        "    return metricas\n",
        "\n",
        "\n",
        "\n",
        "  #Imprime un reporte con cada una de las metricas, en lugar de solo la lista\n",
        "  #sin contexto con los valores.\n",
        "  #Y tiene una mejor presentacion que el otro metodo que tiene el modulo de\n",
        "  #sklearn\n",
        "  def printReporteInd(self,nombreClasificador):\n",
        "    metricas=[]\n",
        "    nombre=\"\"\n",
        "\n",
        "    if nombreClasificador==\"arbol\":\n",
        "      metricas=self.evaluarModelo(\"arbol\")\n",
        "      nombre=\"Arbol de decisiones\"\n",
        "    if nombreClasificador==\"logreg\":\n",
        "      metricas=self.evaluarModelo(\"logreg\")\n",
        "      nombre=\"Regresion Logistica\"\n",
        "    if nombreClasificador==\"svm\":\n",
        "      metricas=self.evaluarModelo(\"svm\")\n",
        "      nombre=\"Support Vector Machine\"\n",
        "\n",
        "    print(\"<<<    REPORTE INDIVIDUAL DEL MODELO: \",nombre,\" >>>> \\n\")\n",
        "    print(\"Accuracy: \",metricas[0])\n",
        "    print(\"Precision: \",metricas[1])\n",
        "    print(\"Recall (sensibilidad): \",metricas[2])\n",
        "    print(\"Especificidad: \",metricas[3])\n",
        "    print(\"F1: \",metricas[4])\n",
        "    #print(\"AUC: \",metricas[5])\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "  #Crea la matriz de confusion para cada uno de los modelos\n",
        "  def mostrarMatrizConfusion(self,nombreClasificador):\n",
        "\n",
        "    if nombreClasificador==\"arbol\":\n",
        "      clasificador=self.arbol\n",
        "      y_predicted=self.y_predicted_arbol\n",
        "    if nombreClasificador==\"logreg\":\n",
        "      clasificador=self.logRec\n",
        "      y_predicted=self.y_predicted_logreg\n",
        "    if nombreClasificador==\"svm\":\n",
        "      clasificador=self.svm\n",
        "      y_predicted=self.y_predicted_svm\n",
        "\n",
        "    matriz=confusion_matrix(self.y_test,y_predicted,labels=clasificador.classes_)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=matriz,display_labels=clasificador.classes_)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "  def mostrarCurvaROC(self,nombreClasificador):\n",
        "\n",
        "    if nombreClasificador==\"arbol\":\n",
        "      clasificador=self.arbol\n",
        "      y_predicted=self.y_predicted_arbol\n",
        "      y_score = clasificador.fit(self.x_train, self.y_train).predict_proba(self.x_train)[:, 1]\n",
        "    if nombreClasificador==\"logreg\":\n",
        "      clasificador=self.logRec\n",
        "      y_predicted=self.y_predicted_logreg\n",
        "      y_score = clasificador.fit(self.x_train, self.y_train).predict_proba(self.x_train)[:, 1]\n",
        "    if nombreClasificador==\"svm\":\n",
        "      clasificador=self.svm\n",
        "      y_predicted=self.y_predicted_svm\n",
        "      y_score = clasificador.fit(self.x_train, self.y_train).decision_function(self.x_test)\n",
        "\n",
        "    plot_roc_curve(clasificador, self.x_test, self.y_test)\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Funcion que aun no esta terminada, tiene el objetivo de crear un reporte\n",
        "  #general de los 3 modelos, mostrando el mas eficiente y generando las\n",
        "  #graficas de la matriz de confusion\n",
        "  def reporteGeneral(self):\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "  #Funcion para graficar la ROC, no se va a usar por ahora porque debe\n",
        "  #ser corregida\n",
        "  def mostrarCurvaROC_plus(self,nombreClasificador):\n",
        "\n",
        "    if nombreClasificador==\"arbol\":\n",
        "      clasificador=self.arbol\n",
        "      y_predicted=self.y_predicted_arbol\n",
        "      y_score = clasificador.fit(self.x_train, self.y_train).predict_proba(self.x_train)[:, 1]\n",
        "    if nombreClasificador==\"logreg\":\n",
        "      clasificador=self.logRec\n",
        "      y_predicted=self.y_predicted_logreg\n",
        "      y_score = clasificador.fit(self.x_train, self.y_train).predict_proba(self.x_train)[:, 1]\n",
        "    if nombreClasificador==\"svm\":\n",
        "      clasificador=self.svm\n",
        "      y_predicted=self.y_predicted_svm\n",
        "      y_score = clasificador.fit(self.x_train, self.y_train).decision_function(self.x_test)\n",
        "\n",
        "    #CALCULAR LOS VALORES DE LA CURVA\n",
        "\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    #n_classes = self.y_train.shape[1]\n",
        "    n_classes = 2\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(self.y_test[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])    \n",
        "\n",
        "\n",
        "    #CREAR LA FIGURA CON MATPLOTLIB\n",
        "    \n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(\n",
        "        fpr[2],\n",
        "        tpr[2],\n",
        "        color=\"darkorange\",\n",
        "        lw=lw,\n",
        "        label=\"ROC curve (area = %0.2f)\" % roc_auc[2],\n",
        "    )\n",
        "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"Receiver operating characteristic example\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "    return None\n",
        "\n",
        "\n",
        "#FUNCION DESCARTADA PERO SE MANTIENE POR SI SE REQUIERE REGRESAR A UN INICIO\n",
        "  def printReporteInd_Descartado(self,nombreClasificador):\n",
        "    metricas=[]\n",
        "    nombre=\"\"\n",
        "\n",
        "    if nombreClasificador==\"arbol\":\n",
        "      metricas=self.evaluarArbol()\n",
        "      nombre=\"Arbol de decisiones\"\n",
        "    if nombreClasificador==\"logreg\":\n",
        "      metricas=self.evaluarRegresionLogistica()\n",
        "      nombre=\"Regresion Logistica\"\n",
        "    if nombreClasificador==\"svm\":\n",
        "      metricas=self.evaluarSVM()\n",
        "      nombre=\"Support Vector Machine\"\n",
        "\n",
        "    print(\"<<<    REPORTE INDIVIDUAL DEL MODELO: \",nombre,\" >>>> \\n\")\n",
        "    print(\"Accuracy: \",metricas[0])\n",
        "    print(\"Precision: \",metricas[1])\n",
        "    print(\"Recall (sensibilidad): \",metricas[2])\n",
        "    print(\"Especificidad: \",metricas[3])\n",
        "    print(\"F1: \",metricas[4])\n",
        "    print(\"AUC: \",metricas[5])\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "4Qlbm9cXKLxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "En la siguiente seccion estan primero unas funciones adicionales, de ayuda que \n",
        "se usaran dentro de la clase Versicolor para limpieza, descripcion y ayuda jijiji\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "'''\n",
        "\n",
        "def contarAtipicosColumna(columnaSeries,nombreColumna):\n",
        "    columna=columnaSeries.copy()\n",
        "    q1 = columna.quantile(0.25)\n",
        "    q3 = columna.quantile(0.75)\n",
        "\n",
        "    #Rango intercuartilico\n",
        "    rango = q3-q1 \n",
        "\n",
        "    limiteInferior  = q1-1.5*rango\n",
        "    limiteSuperior = q3+1.5*rango\n",
        "\n",
        "    #Se crea un dataframe/Serie\n",
        "    data=pd.DataFrame(columna)\n",
        "    df = data.loc[ (data[nombreColumna] < limiteInferior) & (data[nombreColumna] > limiteSuperior)  ]\n",
        "\n",
        "    #Se regresa el numero de filas del dataframe\n",
        "    return df.shape[0]\n",
        "\n",
        "#FUNCION PARA ELIMINAR OUTLIERS DE UNA COLUMNA\n",
        "def quitarAtipicosColumna(dataframe, columna):\n",
        "    q1 = dataframe[columna].quantile(0.25)\n",
        "    q3 = dataframe[columna].quantile(0.75)\n",
        "\n",
        "    #Rango intercuartilico\n",
        "    rango = q3-q1 \n",
        "\n",
        "    limiteInferior  = q1-1.5*rango\n",
        "    limiteSuperior = q3+1.5*rango\n",
        "\n",
        "    #Se regresa un nuevo dataframe con sin los valores atipicos de cada columna\n",
        "    #Se crea un dataframe en donde esas columnas estén dentro del limite inferior y mayor\n",
        "    df = dataframe.loc[(dataframe[columna] > limiteInferior) & (dataframe[columna] < limiteSuperior)]\n",
        "\n",
        "    #Se regresa el nuevo dataframe\n",
        "    return df"
      ],
      "metadata": {
        "id": "LL0iPkBfR_9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}